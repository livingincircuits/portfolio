---
customer: "TELUS HEALTH"
title: "Feedback River"
date: "2025-11-10"
task: "Lead UX Researcher"
company: "Developed for TELUS Health"
activities: "Category"
when: "2025"
---

Below is a *portfolio-ready* case study draft built from what’s currently in this folder (“Feedback River”) and its subpages. Where the source material does not provide specifics (for example, exact business KPIs, stakeholder names, or quantified outcomes), I’ve left **tight placeholders** you can fill in once you confirm details or once we can access the PDF contents.[[1]](https://www.notion.so/Feedback-River-16d84d7daa8380e38777f460e00f9b03?pvs=21)[[2]](https://www.notion.so/Topics-18184d7daa838073be48ee6b882f4716?pvs=21)[[3]](https://www.notion.so/Critical-Words-18184d7daa838097b91bee721caa9bac?pvs=21)[[4]](https://www.notion.so/Key-Takeaways-23484d7daa8380f5a91ce73f7d44760e?pvs=21)[[5]](https://www.notion.so/Change-Dates-18984d7daa8380c5b18bdc8a24e67f03?pvs=21)[[6]](https://www.notion.so/Change-Language-1bd84d7daa8380c7bcdbccfb6cdb78f6?pvs=21)

---

### 1) Executive Summary (TL;DR)

**Project title**  

**Feedback River: Operationalising continuous member feedback into a single, reusable decision input**

**The punchline (1 sentence)**  

I created a lightweight system that centralised unfiltered member feedback from multiple sources into one “river”, reducing the friction for teams to build product intuition while explicitly mitigating recency and “loudest voice” bias through structured synthesis and recurring roundups.[[1]](https://www.notion.so/Feedback-River-16d84d7daa8380e38777f460e00f9b03?pvs=21)

**My role**  

Lead UX Researcher and Research Ops partner (system design, taxonomy, analysis prompts, measurement framing).[[1]](https://www.notion.so/Feedback-River-16d84d7daa8380e38777f460e00f9b03?pvs=21)[[3]](https://www.notion.so/Critical-Words-18184d7daa838097b91bee721caa9bac?pvs=21)[[4]](https://www.notion.so/Key-Takeaways-23484d7daa8380f5a91ce73f7d44760e?pvs=21)

**Team / collaborators**  

Cross-functional partners in Product, Design, Content, and Research who needed a reliable, repeatable way to consume ongoing user feedback. *(Add specific names/roles if you can.)*[[1]](https://www.notion.so/Feedback-River-16d84d7daa8380e38777f460e00f9b03?pvs=21)

---

### 2) Challenge & Context

**Problem space (the “why now”)**  

Teams had access to lots of user feedback, but it was fragmented and hard to consume consistently. The result was predictable:

- Low feedback immersion because gathering signals took too much effort.
- Increased risk of biased decision-making from the most recent or most emotionally salient comments (“visibility” bias and recency bias).[[1]](https://www.notion.so/Feedback-River-16d84d7daa8380e38777f460e00f9b03?pvs=21)

**Research goals (knowledge gaps to bridge)**  

1. Make ongoing member feedback **easy to access** in one place without forcing every team to “read everything.”[[1]](https://www.notion.so/Feedback-River-16d84d7daa8380e38777f460e00f9b03?pvs=21)  
2. Create a structure so qualitative feedback can be **synthesised into themes** and translated into action, rather than staying as raw commentary.[[2]](https://www.notion.so/Topics-18184d7daa838073be48ee6b882f4716?pvs=21)  
3. Pair qualitative signals with **lightweight quant** where possible (for example, SUS and satisfaction tracking) to support prioritisation and trend monitoring.[[4]](https://www.notion.so/Key-Takeaways-23484d7daa8380f5a91ce73f7d44760e?pvs=21)[[7]](https://www.notion.so/SUS-1c884d7daa8380d0b13adaa149a63691?pvs=21)

**Constraints**  

- Feedback volume and variability required a system that could scale without becoming a manual research project every time.[[1]](https://www.notion.so/Feedback-River-16d84d7daa8380e38777f460e00f9b03?pvs=21)
- Multilingual input (French Canadian feedback) needed a repeatable translation workflow to avoid excluding portions of the dataset.[[6]](https://www.notion.so/Change-Language-1bd84d7daa8380c7bcdbccfb6cdb78f6?pvs=21)
- Dates coming from external sources needed normalisation to support sorting, trending, and analysis.[[5]](https://www.notion.so/Change-Dates-18984d7daa8380c5b18bdc8a24e67f03?pvs=21)

---

### 3) Strategic Approach & Methodology (the “why these choices”)

**Method selection (and rationale)**  

This was an ops + insights hybrid initiative, so I combined:

- **Centralised qualitative repository (“Feedback River”)** to increase feedback immersion and reduce time-to-signal.[[1]](https://www.notion.so/Feedback-River-16d84d7daa8380e38777f460e00f9b03?pvs=21)
- **Theme creation prompts (“Topics”)** to consistently compress raw feedback into a small set of decision-relevant themes (capped at eight to stay usable).[[2]](https://www.notion.so/Topics-18184d7daa838073be48ee6b882f4716?pvs=21)
- **Critical word taxonomy** to make qualitative comments queryable and comparable (especially useful for recurring problem areas like support issues, modality, and trust signals).[[3]](https://www.notion.so/Critical-Words-18184d7daa838097b91bee721caa9bac?pvs=21)
- **Lightweight measurement layer (SUS + satisfaction)** to track movement over time and pair perception with quant trendlines.[[7]](https://www.notion.so/SUS-1c884d7daa8380d0b13adaa149a63691?pvs=21)[[4]](https://www.notion.so/Key-Takeaways-23484d7daa8380f5a91ce73f7d44760e?pvs=21)

**Participant / data strategy**  

Rather than recruiting new participants, I operationalised *existing* member feedback streams into a single channel designed for continuous intake.[[1]](https://www.notion.so/Feedback-River-16d84d7daa8380e38777f460e00f9b03?pvs=21)

**Lead-specific leverage**  

I designed the system so teams could reuse it without needing a researcher embedded full-time, while still protecting decision quality via explicit bias warnings and a stated practice of UXR-led roundups/synthesis (instead of raw, unaudited immersion driving priorities).[[1]](https://www.notion.so/Feedback-River-16d84d7daa8380e38777f460e00f9b03?pvs=21)

---

### 4) The “Messy Middle” (process & collaboration)

**Stakeholder alignment**  

A key challenge in continuous feedback programs is that stakeholders often want “a single source of truth” *and* want it fast. I aligned expectations by positioning the river as:

- A **product-intuition building channel** (quick immersion, not exhaustive reading).[[1]](https://www.notion.so/Feedback-River-16d84d7daa8380e38777f460e00f9b03?pvs=21)
- A system that **requires synthesis** to avoid biased interpretation, with UXR responsible for periodic roundups where possible.[[1]](https://www.notion.so/Feedback-River-16d84d7daa8380e38777f460e00f9b03?pvs=21)

**The pivot / risk management**  

Instead of treating all feedback as equal, I explicitly documented the risk of recency and “loudest voice” bias and built the workflow around structuring and summarising, not dumping raw data into the organisation.[[1]](https://www.notion.so/Feedback-River-16d84d7daa8380e38777f460e00f9b03?pvs=21)

**Synthesis approach (without the sticky-note photo dump)**  

- Themes were constrained and described (Topics).[[2]](https://www.notion.so/Topics-18184d7daa838073be48ee6b882f4716?pvs=21)
- Vocabulary was standardised through “critical words” so findings could be grouped consistently over time and across sources.[[3]](https://www.notion.so/Critical-Words-18184d7daa838097b91bee721caa9bac?pvs=21)
- Quant summaries were scaffolded via a monthly/quarterly table format to prompt observations and trend interpretation.[[4]](https://www.notion.so/Key-Takeaways-23484d7daa8380f5a91ce73f7d44760e?pvs=21)

---

### 5) Insights & Actionable Recommendations

Because this folder mostly contains the *system* and analysis scaffolding (not the filled findings), I’m framing the portfolio section in a way that still reads as senior-level. You can later swap in 3–4 concrete “Aha” findings once you pull them from the PDFs / sheet exports.

**Key findings (insert your top 3–4)**  

1. **[Finding #1 theme]**: *One-sentence insight that explains a structural issue, not a UI preference.*  
    - Evidence: **[quote/snippet]**
    - Recommendation: **[what changed because of it]**
2. **[Finding #2 theme]**  
    - Evidence: **[quote/snippet]**
    - Recommendation: **[what changed because of it]**
3. **[Finding #3 theme]**  
    - Evidence: **[quote/snippet]**
    - Recommendation: **[what changed because of it]**

**Recommendations that fit this system** (examples that map to your structure)  

- Use the **critical word taxonomy** as a shared language across Product, Support, and UXR so feedback trends can be tracked and compared consistently over time.[[3]](https://www.notion.so/Critical-Words-18184d7daa838097b91bee721caa9bac?pvs=21)
- Keep theme lists intentionally small (eight or fewer) to support prioritisation and prevent taxonomy sprawl.[[2]](https://www.notion.so/Topics-18184d7daa838073be48ee6b882f4716?pvs=21)
- Pair immersion with regular synthesis to avoid biased decision-making from raw data.[[1]](https://www.notion.so/Feedback-River-16d84d7daa8380e38777f460e00f9b03?pvs=21)

---

### 6) Business Impact & Outcomes (Lead-level emphasis)

Your current source material does not include final KPI deltas, but the impact story *is still strong* if you write it as “decision enablement + research multiplication,” and then add metrics when you have them.

**The “So what?” (measurable outcomes to add when available)**  

- Reduced time to insight: **[X hours/week saved]** by eliminating ad-hoc searching across sources.
- Increased feedback immersion: **[Y teams adopting / Z monthly active viewers]** because the system removed friction.[[1]](https://www.notion.so/Feedback-River-16d84d7daa8380e38777f460e00f9b03?pvs=21)
- Better prioritisation quality: fewer roadmap swings driven by recency bias, because synthesis became the norm.[[1]](https://www.notion.so/Feedback-River-16d84d7daa8380e38777f460e00f9b03?pvs=21)
- Quant tracking established: monthly/quarterly satisfaction and SUS scaffolding created a baseline for trend monitoring.[[4]](https://www.notion.so/Key-Takeaways-23484d7daa8380f5a91ce73f7d44760e?pvs=21)[[7]](https://www.notion.so/SUS-1c884d7daa8380d0b13adaa149a63691?pvs=21)

**Product / organisational influence**  

- Established a repeatable mechanism for UXR to deliver periodic roundups rather than one-off “please analyse these comments” requests.[[1]](https://www.notion.so/Feedback-River-16d84d7daa8380e38777f460e00f9b03?pvs=21)
- Created reusable workflows for translation and date normalisation so data hygiene would not block analysis.[[6]](https://www.notion.so/Change-Language-1bd84d7daa8380c7bcdbccfb6cdb78f6?pvs=21)[[5]](https://www.notion.so/Change-Dates-18984d7daa8380c5b18bdc8a24e67f03?pvs=21)

**Reflections (maturity + what you’d do differently)**  

- Continuous feedback is powerful, but **dangerous without synthesis**. Naming the bias risks explicitly is part of senior practice.[[1]](https://www.notion.so/Feedback-River-16d84d7daa8380e38777f460e00f9b03?pvs=21)
- Next iteration: integrate behavioural analytics to triangulate self-report (only include this if true for your context).
- Next iteration: define ownership and cadence for roundups so the river remains “alive” rather than a static dumping ground.[[1]](https://www.notion.so/Feedback-River-16d84d7daa8380e38777f460e00f9b03?pvs=21)


<figure class="figure">
	<img src="./perks-data.png">
    <figcaption>data</figcaption>
</figure>

