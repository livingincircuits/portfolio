---
customer: "TELUS HEALTH"
title: "UXPI"
date: "2025-11-20"
task: "Lead UX Researcher"
company: "Developed for TELUS Health"
activities: "Category"
when: "2025"
---

Below is a Lead-level portfolio case study draft built from what’s in this folder (Q1 2025 UXPI page, subpages, the UXPI report PDF, and the attached session video). Where the folder does not provide details (for example, roadmap outcomes), I’ve left crisp placeholders you can fill in later.

---

## 1) Executive Summary (TL;DR)

**Project title**  

**UXPI Benchmarking: Establishing a UX Performance Baseline for Telus Health One (Member Experience) vs Competitors**[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

**The punchline**  

Created the first UXPI benchmark for Telus Health One to replace opinion-driven prioritisation with a repeatable, competitor-referenced performance index, revealing that content findability and navigation were key drivers of lower task efficiency and loyalty. (Baseline: **UXPI 61** for TH1 vs **Lyra 73** and **Supportlinc 69**.)[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

**Your role**  

Lead UX Researcher. Designed and executed a global competitive benchmark. Built the measurement model (behaviour + attitudinal) and translated results into prioritised recommendations and “quick wins.”[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)[[2]](https://www.notion.so/UXPI-Quick-Wins-Table-1ce84d7daa838053ba7fdd177c0bf6ca?pvs=21)

**Team / collaborators**  

Employer Experience Design (UXR). Cross-functional partners not fully specified in this folder (add PM, Design, Engineering names/roles here).[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

---

## 2) The Challenge & Context

**The problem space (the “why now”)**  

The team needed a single, defensible way to measure UX quality over time and benchmark Telus Health One against top competitors, so prioritisation could be driven by evidence rather than gut feel.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

**Research goals (knowledge gaps)**  

- Establish a baseline **UXPI score** for TH1 and competitor set to track UX improvements over time.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)
- Understand **where TH1 underperforms** on critical journeys (content findability, counselling booking, self-help programs, urgent care).[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)
- Identify the **biggest drivers of loyalty** and where usability issues create drop-off risk.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

**Constraints / realism**  

- Benchmarking was a **snapshot in time** for a specific experience/version (limits longitudinal inference).[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)
- Controlled study context may not reflect real-world conditions.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)
- Scope limited to **four tasks**, which may not cover edge cases or all critical journeys.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

---

## 3) Strategic Approach & Methodology (the “why this method”)

**Method selection (why benchmarking + mixed measures)**  

You used a **benchmark study** to quantify experience quality and create a repeatable KPI-like index that combines:  

- **Behavioural effectiveness** (task success)
- **Attitudinal measures** (ease of use, trust, appearance, loyalty via SUPR-Q + NPS elements)

This directly supports executive decision-making and trend tracking over time, not just point-in-time usability feedback.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

**Study design**  

- **n = 200** total participants, **50 per app** (TH1 + three competitors).[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)
- Global employee sample across key regions (Canada, USA, UK, Australia).[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)
- Participants completed 4 scenario-based tasks, then a survey to calculate UXPI.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

**Tasks (what you benchmarked)**  

1. Find a specific article  
2. Set up a meeting with a counsellor  
3. Find a self-help program  
4. Find help for urgent situations[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

**Lead-specific framing (what makes this “Lead”)**  

- Built a **measurement system** (UXPI) intended to scale to 250 participants and to be reused over time.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)
- Designed the study so results could drive **prioritisation** and **comparative product strategy**, not only UI tweaks.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

---

## 4) The “Messy Middle” (Process & Collaboration)

Use this section to demonstrate influence. The folder gives you strong raw material for the *ambiguity* story:

**Stakeholder alignment (positioning) — suggested narrative**  

- Aligned stakeholders around a single question: “How good is the TH1 experience relative to competitors, and what must change to improve loyalty and task efficiency?”[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)
- Framed outcomes in exec-friendly language: benchmarking, index score, and prioritisation focus areas.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

**The pivot (where reality surprised you)**  

- TH1 showed **good success** on urgent care (80%), but still had user confusion and inefficiency, indicating that “success rate” alone was not enough and time-on-task + navigation patterns mattered.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)
- Users often defaulted to **search-as-Google mental models**, and when search did not behave as expected, it undermined navigation recovery and trust.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

**Synthesis (what you did that’s more than “sticky notes”)**  

- Used task-level outcome metrics (success, difficulty ratings, time-on-task) plus qualitative observations and quotes to explain *why* the numbers looked the way they did.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)
- Produced experience maps per task (common patterns, errors, and emotional response) to make the breakdowns actionable for product/design.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

---

## 5) Insights & Actionable Recommendations

Aim for 3–4 “structural” insights. Here are four you can confidently support from the report:

### Insight 1: TH1’s information architecture does not provide reliable “information scent,” so users loop, click randomly, and take longer

**Evidence**  

- Users reported “going in circles,” and TH1 users generally took longer on tasks than competitors.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)
- Many missed key pathways like “Go to Library,” relying on trial and error.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

**Recommendation bridge**  

- Rework navigation and IA to reduce cognitive load and improve flow consistency.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

### Insight 2: Content volume is not the problem; *content organisation and relevance* are

**Evidence**  

- Users appreciated comprehensive features but found information overwhelming and poorly organised.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)
- Low relevance of homepage/content-heavy areas was a factor in task failure.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

**Recommendation bridge**  

- Improve content organisation and apply progressive disclosure to reduce overwhelm.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

### Insight 3: Labels and mental models (“Care”, “Program”, “Wellbeing”, “Programmes”) create avoidable misroutes

**Evidence**  

- “Programmes” under Wellbeing was frequently missed; users confused by “Your program,” “My Care,” and related naming.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)
- Users entered counselling flows when trying to find articles or programs.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

**Recommendation bridge**  

- Standardise terminology, test labels regionally, and strengthen wayfinding cues.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

### Insight 4: Loyalty is tightly linked to clarity of value proposition and an empathetic healthcare tone, not just usability

**Evidence**  

- Low loyalty tied to navigation difficulty and lack of clarity about purpose/value proposition.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)
- Users explicitly requested a more empathetic experience in sensitive contexts.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

**Recommendation bridge**  

- Enhance onboarding and value proposition communication; improve tone and “human-ness” of key moments.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

**Quick wins angle (what engineering can act on now)**  

Your “UXPI Quick Wins Table” already translates findings into user needs and implementable ideas (for example, clearer pathways to the library, improved search expectations, clearer CTAs/labels).[[2]](https://www.notion.so/UXPI-Quick-Wins-Table-1ce84d7daa838053ba7fdd177c0bf6ca?pvs=21)

---

## 6) Business Impact & Outcomes (what’s missing + how to present it)

The folder provides *baseline performance* and a clear prioritisation narrative, but it does **not** include post-launch outcomes. Here’s how to write this section honestly while still sounding Lead-level:

### What you can claim from the artefacts (now)

**Impact delivered immediately**

- Established a **repeatable benchmark** (UXPI) to measure UX over time and against competitors, enabling prioritisation based on evidence.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)
- Identified where TH1 underperforms and why, producing **four high-level recommendation areas** (content organisation, homepage direction, IA, onboarding/value prop).[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

### What you should add (if you have it elsewhere)

Fill in one or two measurable outcomes, such as:

- Roadmap changes: “Top 2 navigation/IA initiatives moved into H1 planning.”
- Efficiency savings: “Prevented investing in X by showing misalignment with user mental models.”
- Product metrics: improvements in task success, time-on-task, retention, support contact rate, or engagement with resources.

### Reflections (strong Lead signal)

- What you learned about research maturity: moving from ad hoc feedback to **benchmark-driven decision-making** and a shared definition of “good UX.”[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)
- What you would do differently: expand tasks, validate in-the-wild behaviour, broaden segments, or add longitudinal tracking to connect UXPI changes to retention/engagement.[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)

---

## Optional: Portfolio-safe artefacts you can include (based on what’s in the folder)

- 1 slide of the **UXPI benchmark score comparison** (TH1 vs competitors).[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)
- 1 slide showing **task success + time-on-task** as the “performance story.”[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)
- 1 screenshot of an **experience map** table (cropped, readable).[[1]](https://www.notion.so/Q1-2025-21d84d7daa838068beace04943594a6c?pvs=21)
- A short clip from the **highlights reel / session video**, if consent and policy allow.[[3]](https://www.notion.so/Curalinc-Video-Link-24584d7daa83808d83f1f3260f4c0717?pvs=21)

---

## 3 key gaps to resolve (so the case study lands as “Lead”)

1. **Stakeholder influence story:** who you convinced, what decision changed, and how you presented trade-offs. (Names and decision moments are not in this folder.)  
2. **Outcome metrics after recommendations:** what shipped and what moved (roadmap, conversion, retention, support).  
3. **Your scaling/multiplying moves:** did UXPI become a cadence, a dashboard, a quarterly benchmark, or a shared KPI?

If you point me to where the roadmap/launch outcomes live (even a separate page or meeting notes), I can rewrite section 6 with concrete impact and stakeholder influence without guessing.

<figure class="figure">
	<img src="./perks-data.png">
    <figcaption>data</figcaption>
</figure>

